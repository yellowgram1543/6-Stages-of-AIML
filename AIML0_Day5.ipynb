{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIgh4WJcVKYwu3Ks9jIeBK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yellowgram1543/6-Stages-of-AIML/blob/main/AIML0_Day5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pandas Summarizing and Computing Descriptive Statistics"
      ],
      "metadata": {
        "id": "r6_5eL1cekxX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LVMW-haeejS",
        "outputId": "e420c8e7-df82-4bcc-99c1-721a38dc44c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   A   B    C\n",
            "0  1  10  100\n",
            "1  2  20  200\n",
            "2  3  30  300\n",
            "3  4  40  400\n",
            "4  5  50  500\n",
            "\n",
            "\n",
            "A      15\n",
            "B     150\n",
            "C    1500\n",
            "dtype: int64\n",
            "\n",
            "\n",
            "A      3.0\n",
            "B     30.0\n",
            "C    300.0\n",
            "dtype: float64\n",
            "\n",
            "\n",
            "A      3.0\n",
            "B     30.0\n",
            "C    300.0\n",
            "dtype: float64\n",
            "\n",
            "\n",
            "A      1.581139\n",
            "B     15.811388\n",
            "C    158.113883\n",
            "dtype: float64\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create sample DataFrame with numeric data\n",
        "df = pd.DataFrame({\n",
        "    'A': [1, 2, 3, 4, 5],\n",
        "    'B': [10, 20, 30, 40, 50],\n",
        "    'C': [100, 200, 300, 400, 500]\n",
        "})\n",
        "print(df)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Calculate sum of each column\n",
        "column_sums = df.sum()\n",
        "# Compute sum for each numeric column\n",
        "print(column_sums)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Calculate mean of each column\n",
        "column_means = df.mean()\n",
        "# Compute arithmetic mean for each numeric column\n",
        "print(column_means)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Calculate median of each column\n",
        "column_medians = df.median()\n",
        "# Compute median (50th percentile) for each numeric column\n",
        "print(column_medians)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Calculate standard deviation of each column\n",
        "column_std = df.std()\n",
        "# Compute sample standard deviation for each numeric column\n",
        "print(column_std)\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comprehensive Descriptive Statistics**"
      ],
      "metadata": {
        "id": "V7ypxLFIe823"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate comprehensive summary statistics\n",
        "summary_stats = df.describe()\n",
        "# Get count, mean, std, min, 25%, 50%, 75%, max for numeric columns\n",
        "print(summary_stats)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Include all data types in describe\n",
        "df_mixed = pd.DataFrame({\n",
        "    'numeric': [1, 2, 3, 4, 5],\n",
        "    'categorical': ['A', 'B', 'A', 'C', 'B'],\n",
        "    'boolean': [True, False, True, True, False]\n",
        "})\n",
        "print(df_mixed)\n",
        "print(\"\\n\")\n",
        "\n",
        "all_stats = df_mixed.describe(include='all')\n",
        "# Include statistics for all data types including categorical\n",
        "print(all_stats)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Describe only categorical columns\n",
        "cat_stats = df_mixed.describe(include=['object', 'bool'])\n",
        "# Get statistics specifically for non-numeric columns\n",
        "print(cat_stats)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zgkLf2je8he",
        "outputId": "6d9b7ccc-763d-4c37-baf7-0710c5f5cf81"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              A          B           C\n",
            "count  5.000000   5.000000    5.000000\n",
            "mean   3.000000  30.000000  300.000000\n",
            "std    1.581139  15.811388  158.113883\n",
            "min    1.000000  10.000000  100.000000\n",
            "25%    2.000000  20.000000  200.000000\n",
            "50%    3.000000  30.000000  300.000000\n",
            "75%    4.000000  40.000000  400.000000\n",
            "max    5.000000  50.000000  500.000000\n",
            "\n",
            "\n",
            "   numeric categorical  boolean\n",
            "0        1           A     True\n",
            "1        2           B    False\n",
            "2        3           A     True\n",
            "3        4           C     True\n",
            "4        5           B    False\n",
            "\n",
            "\n",
            "         numeric categorical boolean\n",
            "count   5.000000           5       5\n",
            "unique       NaN           3       2\n",
            "top          NaN           A    True\n",
            "freq         NaN           2       3\n",
            "mean    3.000000         NaN     NaN\n",
            "std     1.581139         NaN     NaN\n",
            "min     1.000000         NaN     NaN\n",
            "25%     2.000000         NaN     NaN\n",
            "50%     3.000000         NaN     NaN\n",
            "75%     4.000000         NaN     NaN\n",
            "max     5.000000         NaN     NaN\n",
            "\n",
            "\n",
            "       categorical boolean\n",
            "count            5       5\n",
            "unique           3       2\n",
            "top              A    True\n",
            "freq             2       3\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advanced Statistical Measures**"
      ],
      "metadata": {
        "id": "4sjxJ0F3fcGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame with more varied data\n",
        "df_advanced = pd.DataFrame({\n",
        "    'values': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    'weights': [0.1, 0.2, 0.1, 0.3, 0.1, 0.05, 0.05, 0.05, 0.03, 0.02]\n",
        "})\n",
        "print(df_advanced)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Calculate variance\n",
        "variance = df_advanced['values'].var()\n",
        "# Compute sample variance of the values column\n",
        "print(variance)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Calculate skewness (measure of asymmetry)\n",
        "skewness = df_advanced['values'].skew()\n",
        "# Compute skewness to measure distribution asymmetry\n",
        "print(skewness)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Calculate kurtosis (measure of tail heaviness)\n",
        "kurtosis = df_advanced['values'].kurt()\n",
        "# Compute kurtosis to measure distribution tail weight\n",
        "print(kurtosis)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Calculate quantiles\n",
        "quantiles = df_advanced['values'].quantile([0.25, 0.5, 0.75, 0.9])\n",
        "# Compute specific quantiles (25th, 50th, 75th, 90th percentiles)\n",
        "print(quantiles)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoHFfu62fdha",
        "outputId": "34ebf501-8084-47ec-d377-ab0b6f05a670"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   values  weights\n",
            "0       1     0.10\n",
            "1       2     0.20\n",
            "2       3     0.10\n",
            "3       4     0.30\n",
            "4       5     0.10\n",
            "5       6     0.05\n",
            "6       7     0.05\n",
            "7       8     0.05\n",
            "8       9     0.03\n",
            "9      10     0.02\n",
            "\n",
            "\n",
            "9.166666666666666\n",
            "\n",
            "\n",
            "0.0\n",
            "\n",
            "\n",
            "-1.2000000000000002\n",
            "\n",
            "\n",
            "0.25    3.25\n",
            "0.50    5.50\n",
            "0.75    7.75\n",
            "0.90    9.10\n",
            "Name: values, dtype: float64\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Correlation and Covariance**"
      ],
      "metadata": {
        "id": "aijpx8DFfl0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame with correlated variables\n",
        "np.random.seed(42)\n",
        "df_corr = pd.DataFrame({\n",
        "    'X': np.random.randn(100),\n",
        "    'Y': np.random.randn(100),\n",
        "    'Z': np.random.randn(100)\n",
        "})\n",
        "print(df_corr)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Add some correlation between X and Y\n",
        "df_corr['Y'] = df_corr['X'] * 0.5 + df_corr['Y'] * 0.5\n",
        "\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = df_corr.corr()\n",
        "# Compute pairwise correlation coefficients between columns\n",
        "print(correlation_matrix)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Calculate covariance matrix\n",
        "covariance_matrix = df_corr.cov()\n",
        "# Compute pairwise covariance between columns\n",
        "print(covariance_matrix)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Calculate correlation with specific method\n",
        "spearman_corr = df_corr.corr(method='spearman')\n",
        "# Compute Spearman rank correlation instead of Pearson\n",
        "print(spearman_corr)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1R05SBB0fnje",
        "outputId": "2b6d2ae4-c894-48e4-b18c-b0ddbf048e19"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           X         Y         Z\n",
            "0   0.496714 -1.415371  0.357787\n",
            "1  -0.138264 -0.420645  0.560785\n",
            "2   0.647689 -0.342715  1.083051\n",
            "3   1.523030 -0.802277  1.053802\n",
            "4  -0.234153 -0.161286 -1.377669\n",
            "..       ...       ...       ...\n",
            "95 -1.463515  0.385317 -0.692910\n",
            "96  0.296120 -0.883857  0.899600\n",
            "97  0.261055  0.153725  0.307300\n",
            "98  0.005113  0.058209  0.812862\n",
            "99 -0.234587 -1.142970  0.629629\n",
            "\n",
            "[100 rows x 3 columns]\n",
            "\n",
            "\n",
            "          X         Y         Z\n",
            "X  1.000000  0.635724  0.190840\n",
            "Y  0.635724  1.000000  0.113064\n",
            "Z  0.190840  0.113064  1.000000\n",
            "\n",
            "\n",
            "          X         Y         Z\n",
            "X  0.824770  0.353308  0.187922\n",
            "Y  0.353308  0.374487  0.075022\n",
            "Z  0.187922  0.075022  1.175669\n",
            "\n",
            "\n",
            "          X         Y         Z\n",
            "X  1.000000  0.599640  0.176694\n",
            "Y  0.599640  1.000000  0.130753\n",
            "Z  0.176694  0.130753  1.000000\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handling Missing Values in Statistics**"
      ],
      "metadata": {
        "id": "XCxh1pZtf5nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame with missing values\n",
        "df_missing = pd.DataFrame({\n",
        "    'A': [1, 2, np.nan, 4, 5],\n",
        "    'B': [10, np.nan, 30, np.nan, 50],\n",
        "    'C': [100, 200, 300, 400, np.nan]\n",
        "})\n",
        "print(df_missing)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Calculate mean ignoring NaN values (default behavior)\n",
        "mean_with_na = df_missing.mean()\n",
        "# Compute mean while automatically skipping missing values\n",
        "print(mean_with_na)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Calculate mean treating NaN as zero\n",
        "mean_fill_na = df_missing.fillna(0).mean()\n",
        "# Fill missing values with zero before calculating mean\n",
        "print(mean_fill_na)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Count non-null values in each column\n",
        "non_null_counts = df_missing.count()\n",
        "# Count actual non-missing values per column\n",
        "print(non_null_counts)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Check for any missing values\n",
        "has_missing = df_missing.isnull().any()\n",
        "# Identify columns that contain at least one missing value\n",
        "print(has_missing)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0SxF_DPf8bu",
        "outputId": "5e0d04fe-761c-45a8-c1bd-b18b4cafcebf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     A     B      C\n",
            "0  1.0  10.0  100.0\n",
            "1  2.0   NaN  200.0\n",
            "2  NaN  30.0  300.0\n",
            "3  4.0   NaN  400.0\n",
            "4  5.0  50.0    NaN\n",
            "\n",
            "\n",
            "A      3.0\n",
            "B     30.0\n",
            "C    250.0\n",
            "dtype: float64\n",
            "\n",
            "\n",
            "A      2.4\n",
            "B     18.0\n",
            "C    200.0\n",
            "dtype: float64\n",
            "\n",
            "\n",
            "A    4\n",
            "B    3\n",
            "C    4\n",
            "dtype: int64\n",
            "\n",
            "\n",
            "A    True\n",
            "B    True\n",
            "C    True\n",
            "dtype: bool\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Group-wise Statistics**"
      ],
      "metadata": {
        "id": "5E0mLJQagsgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame with groups\n",
        "df_groups = pd.DataFrame({\n",
        "    'category': ['A', 'A', 'B', 'B', 'C', 'C', 'A', 'B'],\n",
        "    'value1': [10, 15, 20, 25, 30, 35, 12, 22],\n",
        "    'value2': [100, 150, 200, 250, 300, 350, 120, 220]\n",
        "})\n",
        "print(df_groups)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Calculate group-wise means\n",
        "group_means = df_groups.groupby('category').mean()\n",
        "# Compute mean for each numeric column within each category group\n",
        "print(group_means)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Calculate multiple statistics per group\n",
        "group_stats = df_groups.groupby('category').agg({\n",
        "    'value1': ['mean', 'std', 'count'],\n",
        "    'value2': ['min', 'max', 'median']\n",
        "})\n",
        "# Apply multiple aggregation functions to different columns per group\n",
        "print(group_stats)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Calculate overall statistics by group\n",
        "group_describe = df_groups.groupby('category').describe()\n",
        "# Get comprehensive statistics for each group separately\n",
        "print(group_describe)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AGedAvDguDW",
        "outputId": "b2127c48-d648-4307-b6f5-4c324ee48970"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  category  value1  value2\n",
            "0        A      10     100\n",
            "1        A      15     150\n",
            "2        B      20     200\n",
            "3        B      25     250\n",
            "4        C      30     300\n",
            "5        C      35     350\n",
            "6        A      12     120\n",
            "7        B      22     220\n",
            "\n",
            "\n",
            "             value1      value2\n",
            "category                       \n",
            "A         12.333333  123.333333\n",
            "B         22.333333  223.333333\n",
            "C         32.500000  325.000000\n",
            "\n",
            "\n",
            "             value1                 value2            \n",
            "               mean       std count    min  max median\n",
            "category                                              \n",
            "A         12.333333  2.516611     3    100  150  120.0\n",
            "B         22.333333  2.516611     3    200  250  220.0\n",
            "C         32.500000  3.535534     2    300  350  325.0\n",
            "\n",
            "\n",
            "         value1                                                      value2  \\\n",
            "          count       mean       std   min    25%   50%    75%   max  count   \n",
            "category                                                                      \n",
            "A           3.0  12.333333  2.516611  10.0  11.00  12.0  13.50  15.0    3.0   \n",
            "B           3.0  22.333333  2.516611  20.0  21.00  22.0  23.50  25.0    3.0   \n",
            "C           2.0  32.500000  3.535534  30.0  31.25  32.5  33.75  35.0    2.0   \n",
            "\n",
            "                                                                    \n",
            "                mean        std    min    25%    50%    75%    max  \n",
            "category                                                            \n",
            "A         123.333333  25.166115  100.0  110.0  120.0  135.0  150.0  \n",
            "B         223.333333  25.166115  200.0  210.0  220.0  235.0  250.0  \n",
            "C         325.000000  35.355339  300.0  312.5  325.0  337.5  350.0  \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cumulative Statistics**"
      ],
      "metadata": {
        "id": "UM5dOCH1g8Xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create time series-like DataFrame\n",
        "df_cumulative = pd.DataFrame({\n",
        "    'sales': [100, 120, 130, 110, 140, 160, 150, 170],\n",
        "    'expenses': [80, 85, 90, 88, 95, 100, 98, 105]\n",
        "})\n",
        "print(df_cumulative)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Calculate cumulative sum\n",
        "cumulative_sales = df_cumulative['sales'].cumsum()\n",
        "# Compute running total of sales over time\n",
        "print(cumulative_sales)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Calculate cumulative maximum\n",
        "cumulative_max = df_cumulative.cummax()\n",
        "# Track running maximum for each column\n",
        "print(cumulative_max)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Calculate cumulative mean\n",
        "cumulative_mean = df_cumulative.expanding().mean()\n",
        "# Compute expanding mean (mean of all previous values including current)\n",
        "print(cumulative_mean)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Nm0EJYAg95S",
        "outputId": "0c8028f0-cd5f-49c7-d45a-85cbd65be8d4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sales  expenses\n",
            "0    100        80\n",
            "1    120        85\n",
            "2    130        90\n",
            "3    110        88\n",
            "4    140        95\n",
            "5    160       100\n",
            "6    150        98\n",
            "7    170       105\n",
            "\n",
            "\n",
            "0     100\n",
            "1     220\n",
            "2     350\n",
            "3     460\n",
            "4     600\n",
            "5     760\n",
            "6     910\n",
            "7    1080\n",
            "Name: sales, dtype: int64\n",
            "\n",
            "\n",
            "   sales  expenses\n",
            "0    100        80\n",
            "1    120        85\n",
            "2    130        90\n",
            "3    130        90\n",
            "4    140        95\n",
            "5    160       100\n",
            "6    160       100\n",
            "7    170       105\n",
            "\n",
            "\n",
            "        sales   expenses\n",
            "0  100.000000  80.000000\n",
            "1  110.000000  82.500000\n",
            "2  116.666667  85.000000\n",
            "3  115.000000  85.750000\n",
            "4  120.000000  87.600000\n",
            "5  126.666667  89.666667\n",
            "6  130.000000  90.857143\n",
            "7  135.000000  92.625000\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Percentiles and Rank Statistics**"
      ],
      "metadata": {
        "id": "0hg5yIXThakf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame for percentile calculations\n",
        "df_percentiles = pd.DataFrame({\n",
        "    'scores': [85, 92, 78, 96, 88, 73, 91, 82, 89, 94]\n",
        "})\n",
        "print(df_percentiles)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Calculate specific percentiles\n",
        "percentile_90 = df_percentiles['scores'].quantile(0.9)\n",
        "# Get 90th percentile score\n",
        "print(percentile_90)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Calculate rank of each value\n",
        "ranks = df_percentiles['scores'].rank(method='average', ascending=False)\n",
        "# Assign ranks with highest score getting rank 1\n",
        "print(ranks)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Calculate percentile rank\n",
        "percentile_ranks = df_percentiles['scores'].rank(pct=True)\n",
        "# Convert ranks to percentile ranks (0 to 1 scale)\n",
        "print(percentile_ranks)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCli97OMhcvt",
        "outputId": "9064493f-bc0e-4d20-96ec-c5311a591dc5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   scores\n",
            "0      85\n",
            "1      92\n",
            "2      78\n",
            "3      96\n",
            "4      88\n",
            "5      73\n",
            "6      91\n",
            "7      82\n",
            "8      89\n",
            "9      94\n",
            "\n",
            "\n",
            "94.2\n",
            "\n",
            "\n",
            "0     7.0\n",
            "1     3.0\n",
            "2     9.0\n",
            "3     1.0\n",
            "4     6.0\n",
            "5    10.0\n",
            "6     4.0\n",
            "7     8.0\n",
            "8     5.0\n",
            "9     2.0\n",
            "Name: scores, dtype: float64\n",
            "\n",
            "\n",
            "0    0.4\n",
            "1    0.8\n",
            "2    0.2\n",
            "3    1.0\n",
            "4    0.5\n",
            "5    0.1\n",
            "6    0.7\n",
            "7    0.3\n",
            "8    0.6\n",
            "9    0.9\n",
            "Name: scores, dtype: float64\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Unique Values and Frequency Statistics**"
      ],
      "metadata": {
        "id": "auwzcS_Ziudc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame with categorical and numeric data\n",
        "df_freq = pd.DataFrame({\n",
        "    'category': ['A', 'B', 'A', 'C', 'B', 'A', 'C', 'C'],\n",
        "    'status': ['active', 'inactive', 'active', 'active', 'inactive', 'active', 'pending', 'active']\n",
        "})\n",
        "print(df_freq)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Count unique values in categorical column\n",
        "value_counts = df_freq['category'].value_counts()\n",
        "# Get frequency count of each unique category\n",
        "print(value_counts)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Get unique values only\n",
        "unique_values = df_freq['status'].unique()\n",
        "# Extract array of unique status values\n",
        "print(unique_values)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Count unique values per column\n",
        "nunique_counts = df_freq.nunique()\n",
        "# Count number of unique values in each column\n",
        "print(nunique_counts)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Cross-tabulation of two categorical variables\n",
        "crosstab = pd.crosstab(df_freq['category'], df_freq['status'])\n",
        "# Create contingency table showing frequency of category-status combinations\n",
        "print(crosstab)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM5CwmwHivpN",
        "outputId": "8d5bd4ba-945f-47ba-f698-34fc82ce2cfa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  category    status\n",
            "0        A    active\n",
            "1        B  inactive\n",
            "2        A    active\n",
            "3        C    active\n",
            "4        B  inactive\n",
            "5        A    active\n",
            "6        C   pending\n",
            "7        C    active\n",
            "\n",
            "\n",
            "category\n",
            "A    3\n",
            "C    3\n",
            "B    2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n",
            "['active' 'inactive' 'pending']\n",
            "\n",
            "\n",
            "category    3\n",
            "status      3\n",
            "dtype: int64\n",
            "\n",
            "\n",
            "status    active  inactive  pending\n",
            "category                           \n",
            "A              3         0        0\n",
            "B              0         2        0\n",
            "C              2         0        1\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Memory and Data Type Statistics**"
      ],
      "metadata": {
        "id": "OU_Man9qjO5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame with mixed data types\n",
        "df_memory = pd.DataFrame({\n",
        "    'int_col': [1, 2, 3, 4, 5],\n",
        "    'float_col': [1.1, 2.2, 3.3, 4.4, 5.5],\n",
        "    'str_col': ['a', 'b', 'c', 'd', 'e'],\n",
        "    'bool_col': [True, False, True, False, True]\n",
        "})\n",
        "print(df_memory)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Get memory usage of DataFrame\n",
        "memory_usage = df_memory.memory_usage(deep=True)\n",
        "# Calculate actual memory consumption including object overhead\n",
        "print(memory_usage)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Get data types of each column\n",
        "data_types = df_memory.dtypes\n",
        "# Display data type of each column\n",
        "print(data_types)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Get information about DataFrame structure\n",
        "df_info = df_memory.info()\n",
        "# Display comprehensive DataFrame information including memory usage\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c_8TBUSjRG6",
        "outputId": "0dce1745-ae98-43d4-e717-bb20c950042a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   int_col  float_col str_col  bool_col\n",
            "0        1        1.1       a      True\n",
            "1        2        2.2       b     False\n",
            "2        3        3.3       c      True\n",
            "3        4        4.4       d     False\n",
            "4        5        5.5       e      True\n",
            "\n",
            "\n",
            "Index        132\n",
            "int_col       40\n",
            "float_col     40\n",
            "str_col      250\n",
            "bool_col       5\n",
            "dtype: int64\n",
            "\n",
            "\n",
            "int_col        int64\n",
            "float_col    float64\n",
            "str_col       object\n",
            "bool_col        bool\n",
            "dtype: object\n",
            "\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5 entries, 0 to 4\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   int_col    5 non-null      int64  \n",
            " 1   float_col  5 non-null      float64\n",
            " 2   str_col    5 non-null      object \n",
            " 3   bool_col   5 non-null      bool   \n",
            "dtypes: bool(1), float64(1), int64(1), object(1)\n",
            "memory usage: 257.0+ bytes\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom Statistical Functions**"
      ],
      "metadata": {
        "id": "vLmobffjkGyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define custom statistical functions\n",
        "def coefficient_of_variation(series):\n",
        "    \"\"\"Calculate coefficient of variation (std/mean)\"\"\"\n",
        "    return series.std() / series.mean() if series.mean() != 0 else np.nan\n",
        "\n",
        "def iqr(series):\n",
        "    \"\"\"Calculate interquartile range\"\"\"\n",
        "    return series.quantile(0.75) - series.quantile(0.25)\n",
        "\n",
        "# Apply custom functions\n",
        "df_custom = pd.DataFrame({\n",
        "    'group1': [10, 12, 11, 13, 14],\n",
        "    'group2': [20, 25, 18, 22, 24]\n",
        "})\n",
        "\n",
        "cv_stats = df_custom.apply(coefficient_of_variation)\n",
        "# Apply custom coefficient of variation function to each column\n",
        "print(cv_stats)\n",
        "print(\"\\n\")\n",
        "\n",
        "iqr_stats = df_custom.apply(iqr)\n",
        "# Apply custom interquartile range function to each column\n",
        "print(iqr_stats)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Combine built-in and custom functions\n",
        "combined_stats = df_custom.agg({\n",
        "    'group1': ['mean', 'std', coefficient_of_variation],\n",
        "    'group2': ['median', iqr] # Use the function object instead of the string 'iqr'\n",
        "})\n",
        "# Mix built-in and custom functions in aggregation\n",
        "print(combined_stats)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ej1L6Nf0kHZy",
        "outputId": "93ff407b-9cd3-4b4b-ccb7-794747adee6d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "group1    0.131762\n",
            "group2    0.131356\n",
            "dtype: float64\n",
            "\n",
            "\n",
            "group1    2.0\n",
            "group2    4.0\n",
            "dtype: float64\n",
            "\n",
            "\n",
            "                             group1  group2\n",
            "mean                      12.000000     NaN\n",
            "std                        1.581139     NaN\n",
            "coefficient_of_variation   0.131762     NaN\n",
            "median                          NaN    22.0\n",
            "iqr                             NaN     4.0\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}